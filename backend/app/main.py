"""
PLURA - FastAPI Application
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
"""
from contextlib import asynccontextmanager
import time

from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
import structlog

from app.core.config import settings
from app.core.trace_context import generate_trace_id, get_trace_id
from app.core.logger import get_traced_logger
from app.api.v1.router import api_router
from app.db.base import engine, Base

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer(),
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†"""
    logger.info("Starting PLURA application", version=settings.app_version)

    # --- èµ·å‹•æ™‚ãƒ­ã‚°è¿½åŠ  ---
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info("ğŸ¤– PLURA AI Configuration Status")
    logger.info(f"â€¢ FAST Tier    : {settings.get_llm_config('fast')}")
    logger.info(f"â€¢ BALANCED Tier: {settings.get_llm_config('balanced')}")
    logger.info(f"â€¢ DEEP Tier    : {settings.get_llm_config('deep')}")
    logger.info(f"â€¢ OpenAI Key   : {'Set' if settings.openai_api_key else 'Not Set'}")
    logger.info(f"â€¢ Google Proj  : {settings.google_cloud_project or 'Not Set'}")
    logger.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    # ---------------------

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆï¼ˆé–‹ç™ºç”¨ï¼‰
    if settings.environment == "development":
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        logger.info("Database tables created")

    yield

    logger.info("Shutting down PLURA application")


# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = FastAPI(
    title=settings.app_name,
    description="""
    PLURA: è‡ªåˆ†ã ã‘ã®ãƒãƒ¼ãƒˆã‹ã‚‰ã€ã¿ã‚“ãªã®é›†åˆçŸ¥ã¸

    å€‹äººãŒè‡ªåˆ†ã®ãŸã‚ã«è¡Œã†ã€Œè¨˜éŒ²ï¼ˆLogï¼‰ã€ã‚’ã€
    çµ„ç¹”å…¨ä½“ã®ã€Œé›†åˆçŸ¥ï¼ˆWisdom of Crowdsï¼‰ã€ã¸ã¨è‡ªç„¶ã«å¤‰æ›ã™ã‚‹
    ãƒŠãƒ¬ãƒƒã‚¸å…±å‰µãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
    """,
    version=settings.app_version,
    openapi_url=f"{settings.api_v1_prefix}/openapi.json",
    docs_url=f"{settings.api_v1_prefix}/docs",
    redoc_url=f"{settings.api_v1_prefix}/redoc",
    lifespan=lifespan,
)

# --- Trace ID Middleware ---
_request_logger = get_traced_logger("Main")


class TraceIDMiddleware(BaseHTTPMiddleware):
    """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã« trace_id ã‚’ç”Ÿæˆã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã«ä»˜ä¸ã™ã‚‹"""

    async def dispatch(self, request: Request, call_next):
        trace_id = generate_trace_id()
        start = time.monotonic()

        _request_logger.info(
            "Request received",
            metadata={
                "method": request.method,
                "path": request.url.path,
            },
        )

        response: Response = await call_next(request)

        duration_ms = round((time.monotonic() - start) * 1000, 1)
        response.headers["X-Trace-ID"] = trace_id

        _request_logger.info(
            "Response sent",
            metadata={
                "status_code": response.status_code,
                "duration_ms": duration_ms,
            },
        )

        return response


# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.backend_cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Trace ID Middlewareï¼ˆCORSã‚ˆã‚Šå†…å´ã«é…ç½®ï¼‰
app.add_middleware(TraceIDMiddleware)

# APIãƒ«ãƒ¼ã‚¿ãƒ¼ã®ç™»éŒ²
app.include_router(api_router, prefix=settings.api_v1_prefix)


@app.get("/")
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "name": settings.app_name,
        "version": settings.app_version,
        "description": "Knowledge co-creation platform",
        "docs": f"{settings.api_v1_prefix}/docs",
    }


@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    from app.core.llm import llm_manager
    from app.core.llm_provider import LLMUsageRole
    from app.core.embedding import embedding_manager

    llm_providers = {}
    for role in LLMUsageRole:
        config = settings.get_llm_config(role.value)
        llm_providers[role.value] = {
            "provider": config.get("provider"),
            "model": config.get("model"),
        }

    embedding_config = settings.get_embedding_config()

    return {
        "status": "healthy",
        "version": settings.app_version,
        "providers": {
            "llm": llm_providers,
            "embedding": {
                "provider": embedding_config.get("provider"),
                "model": embedding_config.get("model"),
            },
            "google_genai_available": settings.is_google_genai_available(),
            "openai_available": settings.is_openai_available(),
        },
    }
