"""
PLURA - Document Processing Tasks
Private RAG: PDFå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆCelery ã‚¿ã‚¹ã‚¯ï¼‰

å‡¦ç†ãƒ•ãƒ­ãƒ¼:
  1. MinIO ã‹ã‚‰ PDF ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  2. PyMuPDF ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
  3. ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
  4. Embedding â†’ Qdrant æ ¼ç´
  5. Document ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°ï¼ˆchunk_count, page_count, statusï¼‰
"""
import asyncio
import logging
import uuid
from typing import Optional, Tuple

from sqlalchemy import select

from app.workers.celery_app import celery_app
from app.db.base import async_session_maker, engine
from app.models.document import Document, DocumentStatus
from app.models.raw_log import RawLog, LogIntent
from app.services.document_store import document_store
from app.services.layer1.private_rag import private_rag, split_text_into_chunks

logger = logging.getLogger(__name__)


def run_async(coro):
    """éåŒæœŸé–¢æ•°ã‚’åŒæœŸçš„ã«å®Ÿè¡Œ"""
    loop = asyncio.get_event_loop()
    if loop.is_running():
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(asyncio.run, coro)
            return future.result()
    return loop.run_until_complete(coro)


def _extract_pdf_text(pdf_bytes: bytes) -> Tuple[str, int]:
    """
    PyMuPDF ã§PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º

    Returns:
        (extracted_text, page_count)
    """
    import fitz  # PyMuPDF

    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page_count = len(doc)
    text_parts = []

    for page in doc:
        text = page.get_text()
        if text.strip():
            text_parts.append(text)

    doc.close()
    return "\n\n".join(text_parts), page_count


@celery_app.task(bind=True, max_retries=2)
def process_document_task(self, document_id: str, thread_id: Optional[str] = None):
    """
    PDFå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    1. MinIO ã‹ã‚‰ PDF ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    2. ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆPyMuPDFï¼‰
    3. ãƒãƒ£ãƒ³ã‚¯åˆ†å‰² â†’ Embedding â†’ Qdrant æ ¼ç´
    4. Document ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ READY ã«æ›´æ–° + å®Œäº†é€šçŸ¥ RawLog ã‚’åŒä¸€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§è¿½åŠ 
    """
    async def _process():
        await engine.dispose()

        async with async_session_maker() as session:
            result = await session.execute(
                select(Document).where(Document.id == uuid.UUID(document_id))
            )
            doc = result.scalar_one_or_none()

            if not doc:
                logger.error(f"Document not found: {document_id}")
                return {"status": "error", "message": "Document not found"}

            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å‡¦ç†ä¸­ã«æ›´æ–°
            doc.status = DocumentStatus.PROCESSING.value
            await session.commit()

            try:
                # Step 1: MinIO ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                logger.info(f"Downloading PDF from MinIO: {doc.object_key}")
                pdf_bytes = await document_store.download_file(doc.object_key)
                if not pdf_bytes:
                    raise Exception("Failed to download PDF from MinIO")

                # Step 2: ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                logger.info(f"Extracting text from PDF: {document_id}")
                extracted_text, page_count = _extract_pdf_text(pdf_bytes)

                if not extracted_text.strip():
                    raise Exception("No text could be extracted from PDF")

                doc.page_count = page_count

                # Step 3: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰² â†’ Qdrant æ ¼ç´
                logger.info(
                    f"Splitting text into chunks: {document_id} "
                    f"({len(extracted_text)} chars, {page_count} pages)"
                )
                chunks = split_text_into_chunks(extracted_text)

                stored_count = await private_rag.store_chunks(
                    document_id=document_id,
                    user_id=str(doc.user_id),
                    filename=doc.filename,
                    chunks=chunks,
                )

                # Step 4: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ READY ã«æ›´æ–° + å®Œäº†é€šçŸ¥ RawLog ã‚’è¿½åŠ 
                # åŒä¸€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§ã‚³ãƒŸãƒƒãƒˆã™ã‚‹ã“ã¨ã§ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒ
                # READY ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ¤œçŸ¥ã—ãŸæ™‚ç‚¹ã§å¿…ãšå®Œäº†ãƒ­ã‚°ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹
                doc.chunk_count = stored_count
                doc.status = DocumentStatus.READY.value

                log_thread_id = uuid.UUID(thread_id) if thread_id else None
                completion_log = RawLog(
                    user_id=doc.user_id,
                    thread_id=log_thread_id,
                    content="[doc_ready]",
                    content_type="system_notification",
                    assistant_reply=(
                        f"ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€Œ{doc.filename}ã€ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
                        "ã€Œè¦ç´„ã—ã¦ã€ã¨æŒ‡ç¤ºã—ãŸã‚Šã€å†…å®¹ã«ã¤ã„ã¦è³ªå•ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
                    ),
                    intent=LogIntent.LOG,
                    is_analyzed=True,
                    is_processed_for_insight=True,
                    is_structure_analyzed=True,
                )
                session.add(completion_log)
                await session.commit()

                logger.info(
                    f"Document processing complete: {document_id}, "
                    f"pages={page_count}, chunks={stored_count}/{len(chunks)}"
                )
                logger.info(f"Completion notification logged for document: {document_id}")

                return {
                    "status": "success",
                    "document_id": document_id,
                    "page_count": page_count,
                    "chunk_count": stored_count,
                }

            except Exception as e:
                logger.error(
                    f"Error processing document {document_id}: {e}",
                    exc_info=True,
                )
                doc.status = DocumentStatus.ERROR.value
                doc.error_message = str(e)[:1000]
                await session.commit()
                return {"status": "error", "message": str(e)}

    return run_async(_process())


@celery_app.task(bind=True, max_retries=1)
def delete_document_task(self, document_id: str, object_key: str):
    """
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‰Šé™¤ã‚¿ã‚¹ã‚¯

    1. Qdrant ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
    2. MinIO ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    """
    async def _delete():
        await engine.dispose()

        try:
            # Qdrant ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
            await private_rag.delete_document_chunks(document_id)

            # MinIO ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            await document_store.delete_file(object_key)

            logger.info(f"Document fully deleted: {document_id}")
            return {"status": "success", "document_id": document_id}
        except Exception as e:
            logger.error(
                f"Error deleting document {document_id}: {e}",
                exc_info=True,
            )
            return {"status": "error", "message": str(e)}

    return run_async(_delete())
