# MINDYARD Environment Variables

# OpenAI API Key (required for LLM features)
OPENAI_API_KEY=your-openai-api-key

# LLM Model Configuration (Multi-Provider, JSON format)
# Deep: 深い思考が必要な複雑なタスク用（reasoning model）
LLM_CONFIG_DEEP='{"provider": "openai", "model": "gpt-5.2"}'
# Balanced: バランスの取れた処理用
LLM_CONFIG_BALANCED='{"provider": "openai", "model": "gpt-5-mini"}'
# Fast: 素早いレスポンスが必要なタスク用
LLM_CONFIG_FAST='{"provider": "openai", "model": "gpt-5-nano"}'

# Vertex AI (Google Cloud) - Optional
# VERTEX_PROJECT_ID=your-gcp-project
# VERTEX_LOCATION=us-central1

# Example: Using Vertex AI (Gemini) for BALANCED tier
# LLM_CONFIG_BALANCED='{"provider": "vertex", "model": "gemini-1.5-flash"}'

# Embedding Configuration (Multi-Provider, JSON format)
EMBEDDING_CONFIG='{"provider": "openai", "model": "text-embedding-3-small"}'

# Example: Using Vertex AI Embedding
# EMBEDDING_CONFIG='{"provider": "vertex", "model": "text-embedding-004"}'

# Available OpenAI Embedding Models:
# - text-embedding-3-small (1536次元, 推奨)
# - text-embedding-3-large (3072次元, 高精度)

# Available Vertex AI Embedding Models:
# - text-embedding-004 (768次元, 推奨)
# - text-embedding-005 (768次元, 最新)
# - text-multilingual-embedding-002 (768次元, 多言語対応)

# Database (if not using Docker defaults)
DATABASE_URL=postgresql+asyncpg://mindyard:mindyard@localhost:5432/mindyard

# Redis
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# Qdrant Vector Database
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Application
ENVIRONMENT=development
DEBUG=true
SECRET_KEY=change-me-in-production-mindyard-secret-key

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1

# NGROK
NGROK_AUTHTOKEN=ngrok_accesstoken
NGHOST=ngrok_domainname
BACKEND_CORS_ORIGINS=http://localhost:3000,https://${NGHOST}  # ngrokのURLを追加
